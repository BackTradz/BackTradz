"""
File: backend/utils/data_loader.py
Role: Charger des donn√©es OHLC depuis le disque (output/ & output_live/) et,
      si n√©cessaire, d√©clencher une extraction automatique.
Depends:
  - backend/output/<SYMBOL>/<YYYY-MM>/<SYMBOL>_<TF>_<YYYY-MM>.csv
  - backend/output_live/<SYMBOL>/<TF>/*.csv
  - backend.extract.extract_data.extract_data_auto (fallback extraction)
Side-effects:
  - Lecture de CSV depuis le disque.
Returns:
  - pd.DataFrame index√© par Datetime, avec colonnes OHLC + 'time' (requis par le runner).
Notes:
  - Ne modifie pas la logique. Ajout de docstrings & commentaires uniquement.
"""

import os
from datetime import datetime, timedelta
import pandas as pd
from pathlib import Path
from app.extract.extract_data import extract_data_auto
from app.core.paths import OUTPUT_DIR, OUTPUT_LIVE_DIR  # <- DISK paths


def load_csv_filtered(symbol: str, timeframe: str, start_date: str, end_date: str):
    """
    Charge un unique CSV mensuel depuis backend/output, puis filtre par dates.

    Args:
        symbol (str): ex. "XAU"
        timeframe (str): ex. "m5"
        start_date (str): "YYYY-MM-DD"
        end_date (str): "YYYY-MM-DD"

    Returns:
        pd.DataFrame: index Datetime, colonnes OHLC, filtr√© entre start_dt et end_dt.
    """
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")

    month_str = start_dt.strftime("%Y-%m")
    # 2 patterns support√©s:
    #   A) output/<SYM>/<YYYY-MM>/<SYM>_<TF>_<YYYY-MM>.csv
    #   B) output/<SYM>/<TF>/<SYM>_<TF>_<YYYY-MM>.csv
    candA = OUTPUT_DIR / symbol / month_str / f"{symbol}_{timeframe}_{month_str}.csv"
    candB = OUTPUT_DIR / symbol / timeframe / f"{symbol}_{timeframe}_{month_str}.csv"
    file_path = candA if candA.exists() else candB
    if not file_path.exists():
        raise FileNotFoundError(f"‚ùå Fichier introuvable : {file_path}")
    # Lecture + nettoyage minimal
    df = pd.read_csv(file_path)
    df = df[df["Open"] != "GBPUSD=X"]  # nettoyage sp√©cifique √† ta data source
    for col in ["Open", "High", "Low", "Close"]:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df.dropna(inplace=True)

    # Standardise l'index temporel
    df["Datetime"] = pd.to_datetime(df["Datetime"]).dt.tz_localize(None)
    df.set_index("Datetime", inplace=True)

    # Filtre sur la fen√™tre demand√©e
    return df.loc[start_dt:end_dt]


def load_data_or_extract(symbol: str, timeframe: str, start_date: str, end_date: str):
    """
    Charge et fusionne toutes les donn√©es disponibles (output/ + output_live/).
    Si rien n‚Äôest trouv√©, tente une extraction automatique.

    Args:
        symbol, timeframe, start_date, end_date: param√®tres de la p√©riode et de l‚Äôinstrument.

    Returns:
        pd.DataFrame: concat des morceaux trouv√©s, index Datetime tri√©, avec colonne 'time'.

    Raises:
        FileNotFoundError / ValueError si aucune donn√©e exploitable.
    """
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    dfs = []

    print(f"üîé Recherche des donn√©es entre {start_date} et {end_date}")

    # === 1) Lecture mensuelle depuis OUTPUT_DIR (disk)
    month_start = start_dt.replace(day=1)
    current = month_start
    while current <= end_dt:
        month_str = current.strftime("%Y-%m")
        filename = f"{symbol}_{timeframe}_{month_str}.csv"
        # 2 patterns: <SYM>/<YYYY-MM>/... ou <SYM>/<TF>/...
        candA = OUTPUT_DIR / symbol / month_str / filename
        candB = OUTPUT_DIR / symbol / timeframe / filename
        file_path = candA if candA.exists() else candB

        if file_path.exists():
            try:
                print(f"üìÇ Chargement depuis output : {file_path}")
                df = pd.read_csv(file_path)
                df["Datetime"] = pd.to_datetime(df["Datetime"]).dt.tz_localize(None)
                df.set_index("Datetime", inplace=True)
                dfs.append(df)
            except Exception as e:
                print(f"‚ùå Erreur lecture output : {e}")

        # Passe au 1er du mois suivant (truc du 28+4 pour g√©rer tous les mois)
        current = (current.replace(day=28) + pd.Timedelta(days=4)).replace(day=1)

    # === 2) Lecture live depuis OUTPUT_LIVE_DIR/<symbol>/<tf>/*.csv
    live_dir = OUTPUT_LIVE_DIR / symbol / timeframe
    if live_dir.exists():
        for file in live_dir.glob("*.csv"):
            try:
                print(f"üì• Lecture LIVE : {file.name}")
                df = pd.read_csv(file)

                # Supprime lignes parasites (ex: "AUDUSD=" qui trainent)
                df = df[~df.astype(str).apply(lambda row: row.str.contains("AUDUSD=", case=False)).any(axis=1)]

                # Harmonise la colonne temporelle ‚Üí "Datetime"
                if "Datetime" not in df.columns:
                    if "time" in df.columns:
                        df.rename(columns={"time": "Datetime"}, inplace=True)
                    elif "Date" in df.columns:
                        df.rename(columns={"Date": "Datetime"}, inplace=True)
                    else:
                        raise ValueError(f"‚ùå Colonne temporelle manquante dans : {file.name}")

                # Nettoyage temporel
                df["Datetime"] = pd.to_datetime(df["Datetime"], errors="coerce").dt.tz_localize(None)
                df.dropna(subset=["Datetime"], inplace=True)
                df.set_index("Datetime", inplace=True)
                df["time"] = df.index  # requis par le runner_core

                # Filtre par fen√™tre
                filtered_df = df[(df.index >= start_dt) & (df.index <= end_dt)]
                if not filtered_df.empty:
                    dfs.append(filtered_df)
                    print(f"‚úÖ Portion LIVE ajout√©e : {file.name} ({filtered_df.shape[0]} lignes)")

            except Exception as e:
                print(f"‚ùå Erreur lecture fichier live : {file.name} ‚Üí {e}")

    # === 3) Fallback extraction automatique si aucun morceau trouv√©
    if not dfs:
        print(f"‚õè Aucune donn√©e trouv√©e ‚Üí extraction automatique requise")
        df = extract_data_auto(symbol, timeframe, start_date, end_date)

        if df is None or df.empty:
            raise FileNotFoundError("‚ùå Aucune donn√©e extraite")

        # Nettoyages s√©curis√©s (types num√©riques OHLC)
        if isinstance(df, pd.DataFrame) and not df.empty:
            for col in ["Open", "High", "Low", "Close"]:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce")
            df.dropna(subset=["Open", "High", "Low", "Close"], inplace=True)
        else:
            raise ValueError("‚ùå Donn√©es extraites invalides ou vides")

        # Harmonisation "Datetime"
        if "Datetime" not in df.columns:
            if "time" in df.columns:
                df.rename(columns={"time": "Datetime"}, inplace=True)
            elif "Date" in df.columns:
                df.rename(columns={"Date": "Datetime"}, inplace=True)
            else:
                raise ValueError("‚ùå Colonne 'Datetime' introuvable apr√®s extraction")

        # Standardisation finale
        for col in ["Open", "High", "Low", "Close"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        df.dropna(subset=["Open", "High", "Low", "Close"], inplace=True)
        df["Datetime"] = pd.to_datetime(df["Datetime"]).dt.tz_localize(None)
        df.set_index("Datetime", inplace=True)
        dfs.append(df)

    # === 4) Fusion & d√©duplication
    valid_dfs = [df for df in dfs if isinstance(df, pd.DataFrame) and not df.empty]
    if not valid_dfs:
        raise FileNotFoundError("‚ùå Aucun DataFrame valide √† fusionner")

    # Premi√®re passe (doc h√©rit√©e) ‚Äî conserv√©e pour transparence
    full_df = pd.concat(valid_dfs)
    full_df = full_df[~full_df.index.duplicated(keep="first")]
    full_df.sort_index(inplace=True)

    # Deuxi√®me passe (version finale utilis√©e)
    final_df = pd.concat(valid_dfs).sort_index()
    final_df = final_df[~final_df.index.duplicated(keep="last")]
    final_df = final_df.loc[(final_df.index >= start_dt) & (final_df.index <= end_dt)]
    final_df["time"] = final_df.index  # üß† obligatoire pour le runner_core
    print(f"‚úÖ DF final : {final_df.shape}")
    return final_df
